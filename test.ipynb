{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wXveRpR6vAf-","executionInfo":{"status":"ok","timestamp":1602959807601,"user_tz":-480,"elapsed":1304,"user":{"displayName":"Ding Hao Tan","photoUrl":"","userId":"02102124816910855943"}},"outputId":"dadeb43f-a697-46fc-c77f-d24e63bd61da","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["'''Run this if using Google Colab'''\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":107,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0qE9W_HgoA-Q","executionInfo":{"status":"ok","timestamp":1602959809999,"user_tz":-480,"elapsed":3643,"user":{"displayName":"Ding Hao Tan","photoUrl":"","userId":"02102124816910855943"}},"outputId":"5aeaa0ce-4913-47f6-aaa8-cf009e032b58","colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["%cd /content/drive/My Drive/MLDA_Hackathon/Codes\n","!pip install import-ipynb\n","import import_ipynb"],"execution_count":108,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/MLDA_Hackathon/Codes\n","Requirement already satisfied: import-ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-sNiCmafvEYH","executionInfo":{"status":"ok","timestamp":1602959810001,"user_tz":-480,"elapsed":3631,"user":{"displayName":"Ding Hao Tan","photoUrl":"","userId":"02102124816910855943"}}},"source":["from __future__ import print_function, division\n","\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.autograd import Variable\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import time\n","import os\n","import scipy.io\n","import yaml\n","import math\n","#from model import ft_ResNet50,ft_net_dense, ft_net_NAS, PCB\n","import model"],"execution_count":109,"outputs":[]},{"cell_type":"code","metadata":{"id":"daqDsiIHvHx5","executionInfo":{"status":"ok","timestamp":1602959810004,"user_tz":-480,"elapsed":3625,"user":{"displayName":"Ding Hao Tan","photoUrl":"","userId":"02102124816910855943"}},"outputId":"460069c9-3923-49a7-9784-3eb6c28210bb","colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["#fp16\n","try:\n","    from apex.fp16_utils import *\n","except ImportError: # will be 3.x series\n","    print('This is not an error. If you want to use low precision, i.e., fp16, please install the apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0')"],"execution_count":110,"outputs":[{"output_type":"stream","text":["This is not an error. If you want to use low precision, i.e., fp16, please install the apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q0n2iekvvKx_","executionInfo":{"status":"ok","timestamp":1602959810006,"user_tz":-480,"elapsed":3624,"user":{"displayName":"Ding Hao Tan","photoUrl":"","userId":"02102124816910855943"}}},"source":["parser = argparse.ArgumentParser(description='Test')\n","parser.add_argument('--gpu_ids',default='0', type=str,help='gpu_ids: e.g. 0  0,1,2  0,2')\n","parser.add_argument('--which_epoch',default='last', type=str, help='0,1,2,3...or last')\n","parser.add_argument('--test_dir',default='/content/drive/My Drive/MLDA_Hackathon/Codes/Data Set/Market/pytorch',type=str, help='./test_data')\n","parser.add_argument('--name', default='ft_ResNet50', type=str, help='save model path')\n","parser.add_argument('--batchsize', default=256, type=int, help='batchsize')\n","parser.add_argument('--use_dense', action='store_true', help='use densenet121' )\n","parser.add_argument('--PCB', action='store_true', help='use PCB' )\n","parser.add_argument('--multi', action='store_true', help='use multiple query' )\n","parser.add_argument('--fp16', action='store_true', help='use fp16.' )\n","parser.add_argument('--ms',default='1', type=str,help='multiple_scale: e.g. 1 1,1.1  1,1.1,1.2')\n","\n","opt = parser.parse_args(args=[])"],"execution_count":111,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U4g0Iid1vbKZ"},"source":["load config\n","\n","load the training config"]},{"cell_type":"code","metadata":{"id":"6YGw5T86vY5_","executionInfo":{"status":"ok","timestamp":1602959810017,"user_tz":-480,"elapsed":3631,"user":{"displayName":"Ding Hao Tan","photoUrl":"","userId":"02102124816910855943"}}},"source":["config_path = os.path.join('/content/drive/My Drive/MLDA_Hackathon/Codes/Data Set/Market/pytorch/',opt.name,'opts.yaml')\n","with open(config_path, 'r') as stream:\n","        config = yaml.load(stream)\n","opt.fp16 = config['fp16'] \n","opt.PCB = config['PCB']\n","opt.use_dense = config['use_dense']\n","opt.use_NAS = config['use_NAS']\n","opt.stride = config['stride']\n","\n","if 'nclasses' in config: # tp compatible with old config files\n","    opt.nclasses = config['nclasses']\n","else: \n","    opt.nclasses = 751 \n","\n","str_ids = opt.gpu_ids.split(',')\n","#which_epoch = opt.which_epoch\n","name = opt.name\n","test_dir = opt.test_dir"],"execution_count":112,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0QjP1JPCvuLO"},"source":["GPU setting stuff"]},{"cell_type":"code","metadata":{"id":"zMYdMLE4vuX5","executionInfo":{"status":"ok","timestamp":1602959810025,"user_tz":-480,"elapsed":3624,"user":{"displayName":"Ding Hao Tan","photoUrl":"","userId":"02102124816910855943"}},"outputId":"9ebb834e-feac-4180-ad83-fdd2422261f7","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["gpu_ids = []\n","for str_id in str_ids:\n","    id = int(str_id)\n","    if id >=0:\n","        gpu_ids.append(id)\n","\n","print('We use the scale: %s'%opt.ms)\n","str_ms = opt.ms.split(',')\n","ms = []\n","for s in str_ms:\n","    s_f = float(s)\n","    ms.append(math.sqrt(s_f))\n","\n","# set gpu ids\n","if len(gpu_ids)>0:\n","    torch.cuda.set_device(gpu_ids[0])\n","    cudnn.benchmark = True"],"execution_count":113,"outputs":[{"output_type":"stream","text":["We use the scale: 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"APysp3Mgv2jZ"},"source":["Load Data\n","\n"," We will use torchvision and torch.utils.data packages for loading the data.\n"]},{"cell_type":"code","metadata":{"id":"Y1YFJYoJv1mr","executionInfo":{"status":"ok","timestamp":1602959811232,"user_tz":-480,"elapsed":4822,"user":{"displayName":"Ding Hao Tan","photoUrl":"","userId":"02102124816910855943"}}},"source":["data_transforms = transforms.Compose([\n","        transforms.Resize((256,128), interpolation=3),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","\n","        ############### Ten Crop        \n","        #transforms.TenCrop(224),\n","        #transforms.Lambda(lambda crops: torch.stack(\n","         #   [transforms.ToTensor()(crop) \n","          #      for crop in crops]\n","           # )),\n","        #transforms.Lambda(lambda crops: torch.stack(\n","         #   [transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(crop)\n","          #       for crop in crops]\n","          # ))\n","])\n","\n","if opt.PCB:\n","    data_transforms = transforms.Compose([\n","        transforms.Resize((384,192), interpolation=3),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n","    ])\n","\n","\n","data_dir = test_dir\n","\n","if opt.multi:\n","    image_datasets = {x: datasets.ImageFolder( os.path.join(data_dir,x) ,data_transforms) for x in ['gallery','query','multi-query']}\n","    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=opt.batchsize,\n","                                             shuffle=False, num_workers=16) for x in ['gallery','query','multi-query']}\n","else:\n","    image_datasets = {x: datasets.ImageFolder( os.path.join(data_dir,x) ,data_transforms) for x in ['gallery','query']}\n","    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=opt.batchsize,\n","                                             shuffle=False, num_workers=16) for x in ['gallery','query']}\n","\n","class_names = image_datasets['query'].classes\n","\n","use_gpu = torch.cuda.is_available()\n"],"execution_count":114,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mVgS8cZwv_hO"},"source":["# Load model"]},{"cell_type":"code","metadata":{"id":"2I7TP66ov_rC","executionInfo":{"status":"ok","timestamp":1602959811237,"user_tz":-480,"elapsed":4823,"user":{"displayName":"Ding Hao Tan","photoUrl":"","userId":"02102124816910855943"}}},"source":["def load_network(network):\n","    save_path = os.path.join('/content/drive/My Drive/MLDA_Hackathon/Codes/trained_model/ft_ResNet50/',name,'net_%s.pth'%opt.which_epoch)\n","    network.load_state_dict(torch.load(save_path))\n","    return network\n","\n"],"execution_count":115,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bg9OGrhswhp5"},"source":["Extracting features from model"]},{"cell_type":"code","metadata":{"id":"vLpMsxd_weV3","executionInfo":{"status":"ok","timestamp":1602959811238,"user_tz":-480,"elapsed":4820,"user":{"displayName":"Ding Hao Tan","photoUrl":"","userId":"02102124816910855943"}}},"source":["def fliplr(img):\n","    '''flip horizontal'''\n","    inv_idx = torch.arange(img.size(3)-1,-1,-1).long()  # N x C x H x W\n","    img_flip = img.index_select(3,inv_idx)\n","    return img_flip\n","\n","def extract_feature(model,dataloaders):\n","    features = torch.FloatTensor()\n","    count = 0\n","    for data in dataloaders:\n","        img, label = data\n","        n, c, h, w = img.size()\n","        count += n\n","        print(count)\n","        ff = torch.FloatTensor(n,512).zero_().cuda()\n","        if opt.PCB:\n","            ff = torch.FloatTensor(n,2048,6).zero_().cuda() # we have six parts\n","\n","        for i in range(2):\n","            if(i==1):\n","                img = fliplr(img)\n","            input_img = Variable(img.cuda())\n","            for scale in ms:\n","                if scale != 1:\n","                    # bicubic is only  available in pytorch>= 1.1\n","                    input_img = nn.functional.interpolate(input_img, scale_factor=scale, mode='bicubic', align_corners=False)\n","                outputs = model(input_img) \n","                ff += outputs\n","        # norm feature\n","        if opt.PCB:\n","            # feature size (n,2048,6)\n","            # 1. To treat every part equally, I calculate the norm for every 2048-dim part feature.\n","            # 2. To keep the cosine score==1, sqrt(6) is added to norm the whole feature (2048*6).\n","            fnorm = torch.norm(ff, p=2, dim=1, keepdim=True) * np.sqrt(6) \n","            ff = ff.div(fnorm.expand_as(ff))\n","            ff = ff.view(ff.size(0), -1)\n","        else:\n","            fnorm = torch.norm(ff, p=2, dim=1, keepdim=True)\n","            ff = ff.div(fnorm.expand_as(ff))\n","\n","        features = torch.cat((features,ff.data.cpu()), 0)\n","    return features\n","\n","def get_id(img_path):\n","    camera_id = []\n","    labels = []\n","    for path, v in img_path:\n","        #filename = path.split('/')[-1]\n","        filename = os.path.basename(path)\n","        label = filename[0:4]\n","        camera = filename.split('c')[1]\n","        if label[0:2]=='-1':\n","            labels.append(-1)\n","        else:\n","            labels.append(int(label))\n","        camera_id.append(int(camera[0]))\n","    return camera_id, labels\n","\n","gallery_path = image_datasets['gallery'].imgs\n","query_path = image_datasets['query'].imgs\n","\n","gallery_cam,gallery_label = get_id(gallery_path)\n","query_cam,query_label = get_id(query_path)\n","\n","if opt.multi:\n","    mquery_path = image_datasets['multi-query'].imgs\n","    mquery_cam,mquery_label = get_id(mquery_path)"],"execution_count":116,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vEqQMFuSwqDo"},"source":["Load data from trained model"]},{"cell_type":"code","metadata":{"id":"euuu6ffEwvBU","executionInfo":{"status":"error","timestamp":1602959871705,"user_tz":-480,"elapsed":1447,"user":{"displayName":"Ding Hao Tan","photoUrl":"","userId":"02102124816910855943"}},"outputId":"672fee98-832b-4ee1-c6b2-ff089e8a0c4d","colab":{"base_uri":"https://localhost:8080/","height":262}},"source":["print('-------test-----------')\n","if opt.use_dense:\n","    model_structure = ft_net_dense(opt.nclasses)\n","else:\n","    model_structure = model.ft_net_NAS(opt.nclasses)\n","#else:\n","    #model_structure = model.ft_ResNet50(opt.nclasses, stride = opt.stride)\n","\n","if opt.PCB:\n","    model_structure = PCB(opt.nclasses)\n","#if opt.fp16:\n","#    model_structure = network_to_half(model_structure)\n","\n","model = load_network(model_structure)\n","\n","# Remove the final fc layer and classifier layer\n","if opt.PCB:\n","    #if opt.fp16:\n","    #    model = PCB_test(model[1])\n","    #else:\n","        model = PCB_test(model)\n","else:\n","    #if opt.fp16:\n","        #model[1].model.fc = nn.Sequential()\n","        #model[1].classifier = nn.Sequential()\n","    #else:\n","        model.classifier.classifier = nn.Sequential()\n","\n","# Change to test mode\n","model = model.eval()\n","if use_gpu:\n","    model = model.cuda()\n"],"execution_count":118,"outputs":[{"output_type":"stream","text":["-------test-----------\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-118-bda4e0a5d390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft_net_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mft_net_NAS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#model_structure = model.ft_ResNet50(opt.nclasses, stride = opt.stride)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'model' has no attribute 'ft_net_NAS'"]}]},{"cell_type":"code","metadata":{"id":"03Gx8YQlw6Rv","executionInfo":{"status":"aborted","timestamp":1602959811238,"user_tz":-480,"elapsed":4806,"user":{"displayName":"Ding Hao Tan","photoUrl":"","userId":"02102124816910855943"}}},"source":["# Extract feature\n","with torch.no_grad():\n","    gallery_feature = extract_feature(model,dataloaders['gallery'])\n","    query_feature = extract_feature(model,dataloaders['query'])\n","    if opt.multi:\n","        mquery_feature = extract_feature(model,dataloaders['multi-query'])\n","    \n","# Save to Matlab for check\n","result = {'gallery_f':gallery_feature.numpy(),'gallery_label':gallery_label,'gallery_cam':gallery_cam,'query_f':query_feature.numpy(),'query_label':query_label,'query_cam':query_cam}\n","scipy.io.savemat('pytorch_result.mat',result)\n","\n","print(opt.name)\n","result = './model/%s/result.txt'%opt.name\n","os.system('python evaluate_gpu.py | tee -a %s'%result)\n","\n","if opt.multi:\n","    result = {'mquery_f':mquery_feature.numpy(),'mquery_label':mquery_label,'mquery_cam':mquery_cam}\n","    scipy.io.savemat('multi_query.mat',result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D1tT5wXgxKN1"},"source":[""]}]}